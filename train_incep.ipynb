{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import utils\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from dataset import PSFDataset, ToTensor, MinMaxNorm\n",
    "import numpy as np\n",
    "from model_inception import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "n_zernike = 20\n",
    "split = 0.1\n",
    "batch_size = 64 # Increase stability of convergence?\n",
    "dataset_size = 10000\n",
    "num_epochs = 300\n",
    "lr = 0.001\n",
    "\n",
    "model_dir = 'models/baseline_norm/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "data_dir = 'psfs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU support\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Logs\n",
    "log_path = os.path.join(model_dir, 'logs.log')\n",
    "utils.set_logger(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train set size: 9024 | Validation set size: 1024\n"
     ]
    }
   ],
   "source": [
    "# Load dataset:\n",
    "dataset = PSFDataset(root_dir=data_dir, size=dataset_size,\n",
    "                         transform=transforms.Compose([MinMaxNorm(), ToTensor()]))\n",
    "# Ensure reproducibility:\n",
    "random_seed = 42\n",
    "shuffle_dataset = True\n",
    "    \n",
    "# Split train-test:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "    \n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "    \n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, sampler=val_sampler)\n",
    "\n",
    "logging.info('Train set size: %i | Validation set size: %i' % (batch_size*len(train_dataloader), \n",
    "                                                              batch_size*len(val_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model deployed on 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Load convolutional network\n",
    "model = Net()\n",
    "#state_dict = torch.load(os.path.join(model_dir, 'checkpoint.pth'))\n",
    "#new_state_dict = OrderedDict()\n",
    "#for k, v in state_dict.items():\n",
    "#    name = k[7:] # remove module.\n",
    "#    new_state_dict[name] = v\n",
    "#model.load_state_dict(new_state_dict)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    logging.info(\"Model deployed on %d GPUs\" % (torch.cuda.device_count()))\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 0.01 * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "----------\n",
      "train loss: 10679.921 time: 17.919 s\n",
      "val loss: 6660.946 \n",
      "Epoch 1/299\n",
      "----------\n",
      "train loss: 8253.802 time: 15.383 s\n",
      "val loss: 5494.860 \n",
      "Epoch 2/299\n",
      "----------\n",
      "train loss: 7689.164 time: 15.314 s\n",
      "val loss: 5162.320 \n",
      "Epoch 3/299\n",
      "----------\n",
      "train loss: 7380.335 time: 15.668 s\n",
      "val loss: 5045.515 \n",
      "Epoch 4/299\n",
      "----------\n",
      "train loss: 7202.824 time: 15.257 s\n",
      "val loss: 4578.617 \n",
      "Epoch 5/299\n",
      "----------\n",
      "train loss: 7109.747 time: 15.720 s\n",
      "val loss: 4118.489 \n",
      "Epoch 6/299\n",
      "----------\n",
      "train loss: 6998.736 time: 15.528 s\n",
      "val loss: 4594.954 \n",
      "Epoch 7/299\n",
      "----------\n",
      "train loss: 6982.121 time: 15.549 s\n",
      "val loss: 4318.254 \n",
      "Epoch 8/299\n",
      "----------\n",
      "train loss: 6920.840 time: 15.590 s\n",
      "val loss: 5311.163 \n",
      "Epoch 9/299\n",
      "----------\n",
      "train loss: 6848.010 time: 15.322 s\n",
      "val loss: 3970.080 \n",
      "Epoch 10/299\n",
      "----------\n",
      "train loss: 6774.841 time: 15.483 s\n",
      "val loss: 3851.949 \n",
      "Epoch 11/299\n",
      "----------\n",
      "train loss: 6755.358 time: 15.370 s\n",
      "val loss: 4488.349 \n",
      "Epoch 12/299\n",
      "----------\n",
      "train loss: 6694.703 time: 15.221 s\n",
      "val loss: 3596.626 \n",
      "Epoch 13/299\n",
      "----------\n",
      "train loss: 6680.667 time: 15.431 s\n",
      "val loss: 4076.617 \n",
      "Epoch 14/299\n",
      "----------\n",
      "train loss: 6624.040 time: 15.682 s\n",
      "val loss: 4286.410 \n",
      "Epoch 15/299\n",
      "----------\n",
      "train loss: 6622.316 time: 15.427 s\n",
      "val loss: 3083.897 \n",
      "Epoch 16/299\n",
      "----------\n",
      "train loss: 6625.019 time: 15.486 s\n",
      "val loss: 4367.999 \n",
      "Epoch 17/299\n",
      "----------\n",
      "train loss: 6565.499 time: 15.496 s\n",
      "val loss: 3354.405 \n",
      "Epoch 18/299\n",
      "----------\n",
      "train loss: 6583.180 time: 15.814 s\n",
      "val loss: 3630.627 \n",
      "Epoch 19/299\n",
      "----------\n",
      "train loss: 6550.419 time: 15.709 s\n",
      "val loss: 4587.840 \n",
      "Epoch 20/299\n",
      "----------\n",
      "train loss: 6537.173 time: 15.494 s\n",
      "val loss: 3784.907 \n",
      "Epoch 21/299\n",
      "----------\n",
      "train loss: 6518.727 time: 15.665 s\n",
      "val loss: 3478.167 \n",
      "Epoch 22/299\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    \n",
    "    logging.info('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    logging.info('-' * 10)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    log_every = len(train_dataloader)-1\n",
    "    epoch_time = time.time()\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "\n",
    "        zernike = sample_batched['zernike'].type(torch.FloatTensor)\n",
    "        image = sample_batched['image'].type(torch.FloatTensor)\n",
    "        image = image.to(device)\n",
    "        zernike = zernike.to(device)\n",
    "\n",
    "        # Forward pass, backward pass, optimize\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, zernike)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += float(loss)\n",
    "        # Print statistics\n",
    "        if (i_batch + 1) % (log_every) == 0:\n",
    "            logging.info('train loss: %.3f time: %.3f s' %\n",
    "                      (running_loss / log_every, time.time() - epoch_time))\n",
    "            running_loss = 0.0\n",
    "            epoch_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(val_dataloader):\n",
    "\n",
    "        zernike = sample_batched['zernike'].type(torch.FloatTensor)\n",
    "        image = sample_batched['image'].type(torch.FloatTensor)\n",
    "        image = image.to(device)\n",
    "        zernike = zernike.to(device)\n",
    "\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, zernike)\n",
    "        val_loss += float(loss)\n",
    "\n",
    "    # Save best val metrics in a json file in the model directory\n",
    "    accuracy = val_loss / len(val_dataloader)\n",
    "    metrics_json_path = os.path.join(model_dir, \"metrics.json\")\n",
    "    metrics = utils.Params(metrics_json_path)\n",
    "    if not metrics.hasKey(metrics_json_path, 'accuracy') or metrics.accuracy > accuracy:\n",
    "        metrics.accuracy = accuracy\n",
    "        metrics.save(metrics_json_path)\n",
    "        checkpoint_path = os.path.join(model_dir, 'checkpoint.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        \n",
    "    logging.info('val loss: %.3f ' % (val_loss / len(val_dataloader)))\n",
    "    \n",
    "logging.info('Training finished in %.3f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
